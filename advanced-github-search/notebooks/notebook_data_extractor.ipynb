{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nbformat\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cells_by_keyword(notebook_path, keywords):\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "        notebook = nbformat.read(f, as_version=4)\n",
    "    \n",
    "    extracted_data = {keyword: \"\" for keyword in keywords}\n",
    "    \n",
    "    for cell in notebook.cells:\n",
    "        if cell.cell_type == 'markdown':\n",
    "            for keyword in keywords:\n",
    "                if keyword in cell.source:\n",
    "                    extracted_data[keyword] = cell.source.replace(\"\\n\", \" \")\n",
    "    return extracted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_structure(base_directory):\n",
    "    json_result = []\n",
    "    keywords = [\"Table of Content\", \"Exercises\"]\n",
    "\n",
    "    for root, dirs, files in os.walk(base_directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.ipynb'):\n",
    "                notebook_path = os.path.join(root, file)\n",
    "                extracted_data = get_cells_by_keyword(notebook_path, keywords)\n",
    "                \n",
    "                notebook_info = {\n",
    "                    \"local_path\": notebook_path,\n",
    "                    \"github_link\": \"\",  # Add logic to generate GitHub links if needed\n",
    "                    \"name\": os.path.splitext(file)[0],\n",
    "                    \"table_of_content\": extracted_data[\"Table of Content\"],\n",
    "                    \"exercises\": extracted_data[\"Exercises\"]\n",
    "                }\n",
    "                \n",
    "                json_result.append(notebook_info)\n",
    "\n",
    "    return json_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_json_to_file(data, output_filename):\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_directory = '/mnt/c/Users/user/OneDrive/Desktop/github-projects/advanced-github-search/notebooks/08 File Handling'  # Change this to the directory containing notebooks\n",
    "    output_filename = 'notebooks_summary.json'\n",
    "    \n",
    "    notebooks_json = create_json_structure(base_directory)\n",
    "    save_json_to_file(notebooks_json, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook data saved to notebooks_summary.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import nbformat\n",
    "import re\n",
    "\n",
    "def clean_content(content, cell_type):\n",
    "    \"\"\"\n",
    "    Cleans up content by extracting the text based on the cell type (TOC or Exercises).\n",
    "    \n",
    "    Parameters:\n",
    "    - content (str): The raw markdown content of the cell.\n",
    "    - cell_type (str): The type of cell content to clean (\"toc\" or \"exercises\").\n",
    "    \n",
    "    Returns:\n",
    "    - list of str: A list containing the cleaned text of the specified cell type.\n",
    "    \"\"\"\n",
    "    lines = content.splitlines()\n",
    "    cleaned_lines = []\n",
    "\n",
    "    if cell_type == \"toc\":\n",
    "        # Pattern to capture headings in a markdown list for TOC\n",
    "        toc_regex = re.compile(r'^\\s*[-*]\\s*\\[(.*?)\\]\\(.+\\)\\s*$')\n",
    "\n",
    "        for line in lines:\n",
    "            match = toc_regex.match(line)\n",
    "            if match:\n",
    "                cleaned_lines.append(match.group(1))\n",
    "    elif cell_type == \"exercises\":\n",
    "        # Simply return non-empty lines as a list for exercises\n",
    "        cleaned_lines = [line for line in lines if line.strip()]\n",
    "\n",
    "    return cleaned_lines\n",
    "\n",
    "def extract_cells(directory, json_output_path, repo_url):\n",
    "    \"\"\"\n",
    "    Extracts \"Table of Contents\" and \"Exercises\" cells from all Jupyter notebooks in a directory,\n",
    "    cleans them, and saves the information to a JSON file.\n",
    "    \n",
    "    Parameters:\n",
    "    - directory (str): The directory path to search for Jupyter notebooks.\n",
    "    - json_output_path (str): The path to save the output JSON file.\n",
    "    - repo_url (str): The repository URL to include in the JSON output.\n",
    "    \"\"\"\n",
    "    notebook_data = []\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".ipynb\"):\n",
    "                notebook_path = os.path.join(root, file)\n",
    "\n",
    "                try:\n",
    "                    with open(notebook_path, 'r', encoding='utf-8') as nb_file:\n",
    "                        nb = nbformat.read(nb_file, as_version=4)\n",
    "\n",
    "                        toc_content = \"\"\n",
    "                        exercises_content = \"\"\n",
    "\n",
    "                        for cell in nb.cells:\n",
    "                            if cell.cell_type == 'markdown':\n",
    "                                cell_text = cell.source.lower()\n",
    "\n",
    "                                if \"table of contents\" in cell_text:\n",
    "                                    toc_content = clean_content(cell.source, \"toc\")\n",
    "                                elif \"practice exercise\" in cell_text:\n",
    "                                    exercises_content = clean_content(cell.source, \"exercises\")\n",
    "\n",
    "                        notebook_data.append({\n",
    "                            \"local_path\": notebook_path,\n",
    "                            \"name\": os.path.splitext(file)[0],\n",
    "                            \"table_of_content\": toc_content,\n",
    "                            \"exercises\": exercises_content,\n",
    "                            \"github_link\": os.path.join(repo_url, os.path.relpath(notebook_path, directory))\n",
    "                        })\n",
    "                except (nbformat.reader.NotJSONError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {notebook_path}: {e}\")\n",
    "\n",
    "    with open(json_output_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(notebook_data, json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"Notebook data saved to {json_output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    directory_to_search = \"downloaded_files\"  # Directory with notebooks\n",
    "    output_json_file = \"notebooks_summary.json\"  # Output JSON file\n",
    "    repository_url = \"https://github.com/pytopia/Python-Programming\"  # Base repo URL\n",
    "    \n",
    "    extract_cells(directory_to_search, output_json_file, repository_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook data saved to notebooks_summary.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import nbformat\n",
    "\n",
    "def clean_content(content):\n",
    "    \"\"\"\n",
    "    Cleans and returns the text of notebook cells.\n",
    "    \n",
    "    Parameters:\n",
    "    - content (str): The raw content of a notebook cell.\n",
    "\n",
    "    Returns:\n",
    "    - str: Cleaned content as plain text.\n",
    "    \"\"\"\n",
    "    return content.strip()\n",
    "\n",
    "def extract_cells(directory, json_output_path, repo_url):\n",
    "    \"\"\"\n",
    "    Extracts \"Table of Contents\" and \"Practice Exercises\" cells and their details from Jupyter notebooks,\n",
    "    and saves the information to a JSON file.\n",
    "    \n",
    "    Parameters:\n",
    "    - directory (str): Directory path to search for Jupyter notebooks.\n",
    "    - json_output_path (str): Path to save the output JSON file.\n",
    "    - repo_url (str): Base repository URL for GitHub links.\n",
    "    \"\"\"\n",
    "    notebook_data = []\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".ipynb\"):\n",
    "                notebook_path = os.path.join(root, file)\n",
    "\n",
    "                try:\n",
    "                    with open(notebook_path, 'r', encoding='utf-8') as nb_file:\n",
    "                        nb = nbformat.read(nb_file, as_version=4)\n",
    "\n",
    "                        toc_content = \"\"\n",
    "                        practice_exercises = []\n",
    "                        capturing_practice_exercise = False\n",
    "\n",
    "                        for cell in nb.cells:\n",
    "                            if cell.cell_type == 'markdown':\n",
    "                                cell_text = cell.source.lower()\n",
    "\n",
    "                                if \"table of contents\" in cell_text:\n",
    "                                    toc_content = clean_content(cell.source)\n",
    "                                elif \"practice exercise\" in cell_text:\n",
    "                                    # Start capturing from here\n",
    "                                    capturing_practice_exercise = True\n",
    "                                    practice_exercises.append(clean_content(cell.source))\n",
    "                                elif capturing_practice_exercise and \"##\" in cell_text:\n",
    "                                    # Stop capturing if a new section starts\n",
    "                                    capturing_practice_exercise = False\n",
    "\n",
    "                            # Continue capturing practice exercises if the flag is set\n",
    "                            elif capturing_practice_exercise:\n",
    "                                practice_exercises.append(clean_content(cell.source))\n",
    "\n",
    "                        notebook_data.append({\n",
    "                            \"local_path\": notebook_path,\n",
    "                            \"name\": os.path.splitext(file)[0],\n",
    "                            \"table_of_content\": toc_content,\n",
    "                            \"practice_exercises\": practice_exercises,\n",
    "                            \"github_link\": os.path.join(repo_url, os.path.relpath(notebook_path, directory))\n",
    "                        })\n",
    "                except (nbformat.reader.NotJSONError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {notebook_path}: {e}\")\n",
    "\n",
    "    with open(json_output_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(notebook_data, json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"Notebook data saved to {json_output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    directory_to_search = \"downloaded_files\"  # Change this to your directory\n",
    "    output_json_file = \"notebooks_summary.json\"\n",
    "    repository_url = \"https://github.com/pytopia/Python-Programming\"  # Replace with your repository URL\n",
    "\n",
    "    extract_cells(directory_to_search, output_json_file, repository_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook data saved to notebooks_summary.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import nbformat\n",
    "import re\n",
    "\n",
    "def clean_content(content):\n",
    "    \"\"\"\n",
    "    Cleans and returns the text of notebook cells.\n",
    "    \n",
    "    Parameters:\n",
    "    - content (str): The raw content of a notebook cell.\n",
    "\n",
    "    Returns:\n",
    "    - str: Cleaned content as plain text.\n",
    "    \"\"\"\n",
    "    return content.strip()\n",
    "\n",
    "def extract_cells(directory, json_output_path, repo_url):\n",
    "    \"\"\"\n",
    "    Extracts \"Table of Content\" and \"Practice Exercise\" cells from all Jupyter notebooks in a directory,\n",
    "    cleans them, and saves the information to a JSON file.\n",
    "    \n",
    "    Parameters:\n",
    "    - directory (str): The directory path to search for Jupyter notebooks.\n",
    "    - json_output_path (str): The path to save the output JSON file.\n",
    "    - repo_url (str): The repository URL to include in the JSON output.\n",
    "    \"\"\"\n",
    "    notebook_data = []\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".ipynb\"):\n",
    "                notebook_path = os.path.join(root, file)\n",
    "\n",
    "                try:\n",
    "                    with open(notebook_path, 'r', encoding='utf-8') as nb_file:\n",
    "                        nb = nbformat.read(nb_file, as_version=4)\n",
    "\n",
    "                        toc_content = \"\"\n",
    "                        practice_exercises = []\n",
    "                        capturing_practice_exercise = False\n",
    "\n",
    "                        for cell in nb.cells:\n",
    "                            if cell.cell_type == 'markdown':\n",
    "                                cell_text = cell.source.lower()\n",
    "\n",
    "                                if \"table of contents\" in cell_text:\n",
    "                                    toc_content = clean_content(cell.source)\n",
    "                                elif \"practice exercise\" in cell_text:\n",
    "                                    # Start capturing related cells\n",
    "                                    capturing_practice_exercise = True\n",
    "                                    practice_exercises.append(clean_content(cell.source))\n",
    "                                elif capturing_practice_exercise and re.match(r'^\\s*#', cell.source):\n",
    "                                    # Stop capturing if we hit a new distinct markdown section header\n",
    "                                    capturing_practice_exercise = False\n",
    "\n",
    "                            if capturing_practice_exercise:\n",
    "                                # Append all subsequent cells content, both markdown and code\n",
    "                                practice_exercises.append(clean_content(cell.source))\n",
    "\n",
    "                        notebook_data.append({\n",
    "                            \"local_path\": notebook_path,\n",
    "                            \"name\": os.path.splitext(file)[0],\n",
    "                            \"table_of_content\": toc_content,\n",
    "                            \"practice_exercises\": practice_exercises,\n",
    "                            \"github_link\": os.path.join(repo_url, os.path.relpath(notebook_path, directory))\n",
    "                        })\n",
    "                except (nbformat.reader.NotJSONError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {notebook_path}: {e}\")\n",
    "\n",
    "    with open(json_output_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(notebook_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Notebook data saved to {json_output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    directory_to_search = \"downloaded_files\"  # Change this to your directory\n",
    "    output_json_file = \"notebooks_summary.json\"\n",
    "    repository_url = \"https://github.com/pytopia/Python-Programming\"  # Replace with your repository URL\n",
    "\n",
    "    extract_cells(directory_to_search, output_json_file, repository_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook data saved to notebooks_summary.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import nbformat\n",
    "import re\n",
    "\n",
    "def clean_content(content):\n",
    "    \"\"\"\n",
    "    Cleans and returns the text of notebook cells by removing markdown-specific elements and excessive whitespace.\n",
    "    \n",
    "    Parameters:\n",
    "    - content (str): The raw content of a notebook cell.\n",
    "\n",
    "    Returns:\n",
    "    - str: Cleaned content as plain text.\n",
    "    \"\"\"\n",
    "    # Remove redundant whitespace and line breaks\n",
    "    cleaned_content = re.sub(r'\\s+', ' ', content).strip()\n",
    "    # Optionally, remove markdown syntax if needed, e.g., links or list markers\n",
    "    cleaned_content = re.sub(r'\\[.*?\\]\\(.*?\\)', '', cleaned_content)  # removing markdown links\n",
    "    # Remove bullet points or dashes used in lists\n",
    "    cleaned_content = re.sub(r'^[-*]\\s*', '', cleaned_content, flags=re.MULTILINE)\n",
    "    return cleaned_content\n",
    "\n",
    "def extract_cells(directory, json_output_path, repo_url):\n",
    "    \"\"\"\n",
    "    Extracts \"Table of Contents\" and \"Practice Exercise\" cells from all Jupyter notebooks in a directory,\n",
    "    cleans them, and saves the information to a JSON file.\n",
    "    \n",
    "    Parameters:\n",
    "    - directory (str): The directory path to search for Jupyter notebooks.\n",
    "    - json_output_path (str): The path to save the output JSON file.\n",
    "    - repo_url (str): The repository URL to include in the JSON output.\n",
    "    \"\"\"\n",
    "    notebook_data = []\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".ipynb\"):\n",
    "                notebook_path = os.path.join(root, file)\n",
    "\n",
    "                try:\n",
    "                    with open(notebook_path, 'r', encoding='utf-8') as nb_file:\n",
    "                        nb = nbformat.read(nb_file, as_version=4)\n",
    "\n",
    "                        toc_content = \"\"\n",
    "                        practice_exercises = []\n",
    "                        capturing_practice_exercise = False\n",
    "\n",
    "                        for cell in nb.cells:\n",
    "                            if cell.cell_type == 'markdown':\n",
    "                                cell_text = cell.source.lower()\n",
    "\n",
    "                                if \"table of contents\" in cell_text:\n",
    "                                    toc_content = clean_content(cell.source)\n",
    "                                elif \"practice exercise\" in cell_text:\n",
    "                                    # Start capturing related cells\n",
    "                                    capturing_practice_exercise = True\n",
    "                                    practice_exercises.append(clean_content(cell.source))\n",
    "                                elif capturing_practice_exercise and re.match(r'^\\s*#', cell.source):\n",
    "                                    # Stop capturing if we hit a new distinct markdown section header\n",
    "                                    capturing_practice_exercise = False\n",
    "\n",
    "                            if capturing_practice_exercise:\n",
    "                                # Append all subsequent cells content, both markdown and code, cleaned\n",
    "                                practice_exercises.append(clean_content(cell.source))\n",
    "\n",
    "                        notebook_data.append({\n",
    "                            \"local_path\": notebook_path,\n",
    "                            \"name\": os.path.splitext(file)[0],\n",
    "                            \"table_of_content\": toc_content,\n",
    "                            \"practice_exercises\": practice_exercises,\n",
    "                            \"github_link\": os.path.join(repo_url, os.path.relpath(notebook_path, directory))\n",
    "                        })\n",
    "                except (nbformat.reader.NotJSONError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {notebook_path}: {e}\")\n",
    "\n",
    "    with open(json_output_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(notebook_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Notebook data saved to {json_output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    directory_to_search = \"downloaded_files\"  # Change this to your directory\n",
    "    output_json_file = \"notebooks_summary.json\"\n",
    "    repository_url = \"https://github.com/pytopia/Python-Programming\"  # Replace with your repository URL\n",
    "\n",
    "    extract_cells(directory_to_search, output_json_file, repository_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading downloaded_files/Lectures/11 Advanced Topics/-- Advanced Composite Data Types.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/11 Advanced Topics/-- Bitwise Operators.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/11 Advanced Topics/01 List Memory Management.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/11 Advanced Topics/02 Dictionary and Set Hash Table.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/11 Advanced Topics/03 Variable-length Arguments (*args and **kwargs).ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/11 Advanced Topics/04 Namespaces in Python.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/11 Advanced Topics/05 Variable Scope.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/11 Advanced Topics/06 Namespace Dictionaries.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/11 Advanced Topics/07 Modify Variables Out of Scope.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/11 Advanced Topics/08 Recursion.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/11 Advanced Topics/09 The with Statement and Context Managers.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/11 Advanced Topics/10 Dependency Management.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/11 Advanced Topics/25 Basic OOP Concepts.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/11 Advanced Topics/26 Custom Data Types using Classes.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/12 Capstone Project/01 Project Proposal.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/12 Capstone Project/02 Requirements Gathering.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/12 Capstone Project/03 Design and Planning.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/12 Capstone Project/04 Setting Up the Development Environment.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/12 Capstone Project/05 Modular Design and Code Organization.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/12 Capstone Project/06 Coding and Implementation.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/12 Capstone Project/07 Testing and Debugging.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/12 Capstone Project/08 Dcoumentation and User Guide.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/12 Capstone Project/09 Conclusion.ipynb: Notebook does not appear to be JSON: ''\n",
      "Error reading downloaded_files/Lectures/12 Capstone Project/10 Course Wrap-up.ipynb: Notebook does not appear to be JSON: ''\n",
      "Notebook data saved to notebooks_summary.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import nbformat\n",
    "import re\n",
    "\n",
    "def clean_toc(content):\n",
    "    \"\"\"\n",
    "    Cleans up the \"Table of Contents\" content by extracting plain text headings.\n",
    "    \n",
    "    Parameters:\n",
    "    - content (str): The raw markdown content of the TOC cell.\n",
    "    \n",
    "    Returns:\n",
    "    - list of str: A list containing the plain text titles of each TOC entry.\n",
    "    \"\"\"\n",
    "    lines = content.splitlines()\n",
    "    cleaned_lines = []\n",
    "    \n",
    "    # Regular expression to find markdown list items with links\n",
    "    toc_regex = re.compile(r'^\\s*[-*]\\s*\\[(.*?)\\]\\(.*?\\)\\s*$')\n",
    "    \n",
    "    for line in lines:\n",
    "        match = toc_regex.match(line)\n",
    "        if match:\n",
    "            cleaned_lines.append(match.group(1))\n",
    "    \n",
    "    return cleaned_lines\n",
    "\n",
    "def clean_exercise(content):\n",
    "    \"\"\"\n",
    "    Cleans the \"Practice Exercise\" content by removing markdown syntax and excess whitespace.\n",
    "    \n",
    "    Parameters:\n",
    "    - content (str): The raw content of the exercise cell.\n",
    "    \n",
    "    Returns:\n",
    "    - str: Cleaned content as plain text.\n",
    "    \"\"\"\n",
    "    # Remove markdown links and other formatting\n",
    "    cleaned_content = re.sub(r'\\[.*?\\]\\(.*?\\)', '', content)  # Remove markdown links\n",
    "    cleaned_content = re.sub(r'^\\s*[-*]\\s*', '', cleaned_content, flags=re.MULTILINE)  # Remove list markers\n",
    "    cleaned_content = re.sub(r'\\s+', ' ', cleaned_content).strip()  # Reduce whitespace\n",
    "    return cleaned_content\n",
    "\n",
    "def extract_cells(directory, json_output_path, repo_url):\n",
    "    \"\"\"\n",
    "    Extracts \"Table of Contents\" and \"Practice Exercise\" cells from all Jupyter notebooks in a directory,\n",
    "    cleans them, and saves the information to a JSON file.\n",
    "    \n",
    "    Parameters:\n",
    "    - directory (str): The directory path to search for Jupyter notebooks.\n",
    "    - json_output_path (str): The path to save the output JSON file.\n",
    "    - repo_url (str): The repository URL to include in the JSON output.\n",
    "    \"\"\"\n",
    "    notebook_data = []\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".ipynb\"):\n",
    "                notebook_path = os.path.join(root, file)\n",
    "\n",
    "                try:\n",
    "                    with open(notebook_path, 'r', encoding='utf-8') as nb_file:\n",
    "                        nb = nbformat.read(nb_file, as_version=4)\n",
    "\n",
    "                        toc_content = \"\"\n",
    "                        practice_exercises = []\n",
    "                        capturing_exercise = False\n",
    "\n",
    "                        for cell in nb.cells:\n",
    "                            if cell.cell_type == 'markdown':\n",
    "                                cell_text = cell.source.lower()\n",
    "\n",
    "                                if \"table of contents\" in cell_text:\n",
    "                                    toc_content = clean_toc(cell.source)\n",
    "                                elif \"practice exercise\" in cell_text or \"Exercise:\" in cell_text:\n",
    "                                    capturing_exercise = True\n",
    "                                    practice_exercises.append(clean_exercise(cell.source))\n",
    "                                elif capturing_exercise and re.match(r'^\\s*#', cell.source):\n",
    "                                    capturing_exercise = False\n",
    "\n",
    "                            if capturing_exercise:\n",
    "                                practice_exercises.append(clean_exercise(cell.source))\n",
    "\n",
    "                        notebook_data.append({\n",
    "                            \"local_path\": notebook_path,\n",
    "                            \"name\": os.path.splitext(file)[0],\n",
    "                            \"table_of_content\": toc_content,\n",
    "                            \"practice_exercises\": practice_exercises,\n",
    "                            \"github_link\": os.path.join(repo_url, os.path.relpath(notebook_path, directory))\n",
    "                        })\n",
    "                except (nbformat.reader.NotJSONError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {notebook_path}: {e}\")\n",
    "\n",
    "    with open(json_output_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(notebook_data, json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"Notebook data saved to {json_output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    directory_to_search = \"downloaded_files\"  # Change this to your directory\n",
    "    output_json_file = \"notebooks_summary.json\"\n",
    "    repository_url = \"https://github.com/pytopia/Python-Programming\"  # Replace with your repository URL\n",
    "\n",
    "    extract_cells(directory_to_search, output_json_file, repository_url)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytopia_notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
